---
title: "Introduction to BMEmapping"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to BMEmapping}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

Environmental data are often imprecise due to various limitations and uncertainties in the measuring process. As a result, they often consist of a combination of both precise and imprecise information, referred to as hard and soft data, respectively. Often in practice, soft data are characterized as intervals as a simple form to properly preserve the underlying imprecision. For instance, weather stations that record historical climate conditions do not provide exact measurements. The available measurements, in the mean time, are usually subject to various uncertainties and limitations. As a result, environmental and climate data are typically imprecise. Often in practice, soft data are characterized as intervals as a simple form to properly preserve the underlying imprecision. 

The `BMEmapping` package is used make spatial interpolations for unobserved locations using hard and soft-interval data. This vignette provides an overview of basic features in `BMEmapping`. We load `BMEmapping` by running

```{r setup, message=FALSE, warning=FALSE}
library(ggplot2)  # For plots

library(BMEmapping)
```


$~$

## Main Functions

The main functions available in BMEmapping include:

`bme_predict` - predicts the posterior mean/mode and variance of an unobserved location.

`bme_cv` - performs a cross-validation to check model performance.

`posterior_plot` - plots the the posterior density of an unobserved location.


$~$

## A Data Example

To introduce the functionality of `BMEmapping`, we will look at a modeling problem for estimating reliability-targeted snow loads in the state of Utah. The `utah` data that is part of the package and can be accessed by the command

```{r}
data("utah")
head(utah)
```

and the documentation of the `utah` data can be found by invoking the command:

```{r eval=FALSE}
?utah
```


The geographical locations of the measurement locations and the type of measurement they collect are displayed below



$~$
  
## Prediction Exploration
  
The `posterior_plot` functions require the following arguments:
  
* `x`: is the prediction geographic location
* `ch`: is the geographic location of hard data
* `cs`: is the geographic location of soft-interval data
* `zh`: is the hard data values
* `a`: is the lower bounds of the soft-interval data 
* `b`: is the upper bounds of the soft-interval data 
* `model`: type of variogram model (`"exp", "sph", "gau"`)
* `nugget`: is the nugget of the variogram model
* `sill`: is the sill of the variogram model 
* `range`: is the range (or effective range) of the variogram model 

The following arguments are optional:
  
* `nsmax`: is the number soft-interval data allowable in the integration process, If not specified, the default value is 10. Thus, the 10 closest soft data locations to the prediction location are to be used in the integration process. Generally, results for `nsmax` = 10 is very close to that of `nsmax` > 20.

To use `BMEmapping`, the user must first fit a variogram to the data. This involves extracting the variogram model and its corresponding parameters, which include `model`, `nugget`, `sill`, and `range`. A recommended tool for this process is the `gstat` package, which provides robust functionality for variogram fitting. The BMEmapping package supports three types of variogram models: Exponential, Gaussian, and Spherical. Each of these models can be selected based on the characteristics of the spatial data being analyzed.

Using the `utah` data, we can plot the posterior density for location `x = (lat = 394835.1, lon = 4477333)` as

```{r fig.width = 6, fig.height = 4, fig.align='center'}
# prediction location
x <- data.matrix(utah[1, c("lat", "lon")]) 

# hard data locations
ch <- data.matrix(utah[2:40, c("lat", "lon")]) 

# soft data locations
cs <- data.matrix(utah[68:232, c("lat", "lon")])  

# hard data values
zh <- c(utah[2:40, c("center")])

# lower bounds
a <- c(utah[68:232, c("lower")]) 

# upper bounds
b <- c(utah[68:232, c("upper")]) 

# variogram model and parameters
model <- "sph"
nugget <- 0.1184
sill <- 0.3474
range <- 119197

# specify nsmax
nsmax <- 10
nhmax <- 10

# plot posterior pdf
posterior_plot(x, ch, cs, zh, a, b, model, nugget, sill, range, nsmax, nhmax)
```


The `bme_predict` function accepts the same arguments as the `posterior_plot` function, with the addition of a `type` argument, which specifies the preferred type of prediction (either the posterior mean or mode). Using the data provided, we can predict the mean and mode of the posterior density at the location `x = (lat = 394835.1, lon = 4477333)` by:

```{r}
# posterior mode
bme_predict(x, ch, cs, zh, a, b, model, nugget, sill, range, nsmax, nhmax, 
            type = "mode")
```


Cross-validation (CV) is a widely used technique for evaluating the performance and generalizability of a model. It works by splitting the dataset into multiple subsets, or "folds." The model is trained on some of these folds and tested on the remaining fold, with this process repeated for each fold. This approach ensures that the model's performance is not overly influenced by any single subset of the data, thereby minimizing the risk of overfitting.

In this case, we use leave-one-out cross-validation (LOOCV) with the `bme_cv` function. The `bme_cv` function requires that the number of hard data locations be sufficiently large (at least 20). It takes the same arguments as the `bme_predict` function.

Given the data, we can apply the LOOCV technique for predicting the posterior mean as follows:

```{r}
DF <- bme_cv(ch, cs, zh, a, b, model, nugget, sill, range, nsmax, nhmax, 
             type = "mean")
head(DF, 10)
```



